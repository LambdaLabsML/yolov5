[34m[1mbenchmarks: [0mweights=yolov5l.pt, imgsz=640, batch_size=1, data=/home/ubuntu/data/repos/yolov5/data/coco128.yaml, device=0, half=False, test=False, pt_only=False
YOLOv5 🚀 v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

YOLOv5 🚀 v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Fusing layers... 
YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients, 109.1 GFLOPs
[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupt: 100%|██████████[0m[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupt: 100%|██████████[0m
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/128 [00:00<?, ?it/s]                                              Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   2%|▏         | 3/128 [00:00<00:05, 23.01it/s]                                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   6%|▋         | 8/128 [00:00<00:03, 35.58it/s]                                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  10%|█         | 13/128 [00:00<00:02, 41.41it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  14%|█▍        | 18/128 [00:00<00:02, 42.89it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  19%|█▉        | 24/128 [00:00<00:02, 45.49it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  23%|██▎       | 30/128 [00:00<00:02, 47.81it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  28%|██▊       | 36/128 [00:00<00:01, 48.72it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  32%|███▏      | 41/128 [00:00<00:01, 44.59it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  36%|███▌      | 46/128 [00:01<00:01, 45.63it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  40%|███▉      | 51/128 [00:01<00:01, 46.62it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  45%|████▍     | 57/128 [00:01<00:01, 47.84it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  48%|████▊     | 62/128 [00:01<00:01, 48.35it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  52%|█████▏    | 67/128 [00:01<00:01, 47.22it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  56%|█████▋    | 72/128 [00:01<00:01, 45.26it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  60%|██████    | 77/128 [00:01<00:01, 44.74it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  64%|██████▍   | 82/128 [00:01<00:01, 42.27it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  68%|██████▊   | 87/128 [00:01<00:00, 44.04it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  72%|███████▏  | 92/128 [00:02<00:00, 45.00it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  77%|███████▋  | 98/128 [00:02<00:00, 46.98it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  80%|████████  | 103/128 [00:02<00:00, 47.75it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  84%|████████▍ | 108/128 [00:02<00:00, 46.53it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  88%|████████▊ | 113/128 [00:02<00:00, 43.96it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  92%|█████████▏| 118/128 [00:02<00:00, 43.70it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  96%|█████████▌| 123/128 [00:02<00:00, 44.21it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 128/128 [00:02<00:00, 42.92it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 128/128 [00:02<00:00, 44.67it/s]                     
                 all        128        929      0.799      0.702      0.813      0.594
Speed: 0.3ms pre-process, 12.3ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)
Results saved to [1mruns/val/exp225[0m
YOLOv5 🚀 v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Fusing layers... 
YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients, 109.1 GFLOPs

[34m[1mPyTorch:[0m starting from yolov5l.pt with output shape (1, 25200, 85) (89.3 MB)

[34m[1mTorchScript:[0m starting export with torch 1.10.1+cu113...
[34m[1mTorchScript:[0m export success, saved as yolov5l.torchscript (178.2 MB)

Export complete (2.81s)
Results saved to [1m/home/ubuntu/data/repos/yolov5[0m
Detect:          python detect.py --weights yolov5l.torchscript
PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5l.torchscript')
Validate:        python val.py --weights yolov5l.torchscript
Visualize:       https://netron.app
YOLOv5 🚀 v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Loading yolov5l.torchscript for TorchScript inference...
[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupt: 100%|██████████[0m[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupt: 100%|██████████[0m
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/128 [00:00<?, ?it/s]                                              Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   2%|▏         | 3/128 [00:00<00:04, 27.25it/s]                                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   5%|▌         | 7/128 [00:00<00:03, 33.86it/s]                                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   9%|▉         | 12/128 [00:00<00:02, 40.28it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  14%|█▍        | 18/128 [00:00<00:02, 46.52it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  18%|█▊        | 23/128 [00:00<00:02, 43.55it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  23%|██▎       | 29/128 [00:00<00:02, 47.85it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  28%|██▊       | 36/128 [00:00<00:01, 52.29it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  34%|███▎      | 43/128 [00:00<00:01, 55.26it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  39%|███▉      | 50/128 [00:01<00:01, 56.48it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  44%|████▍     | 56/128 [00:01<00:01, 52.44it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  48%|████▊     | 62/128 [00:01<00:01, 50.06it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  53%|█████▎    | 68/128 [00:01<00:01, 52.63it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  59%|█████▊    | 75/128 [00:01<00:00, 55.47it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  64%|██████▍   | 82/128 [00:01<00:00, 57.76it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  70%|██████▉   | 89/128 [00:01<00:00, 59.54it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  74%|███████▍  | 95/128 [00:01<00:00, 59.46it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  79%|███████▉  | 101/128 [00:01<00:00, 56.98it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  84%|████████▍ | 108/128 [00:02<00:00, 58.47it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  90%|████████▉ | 115/128 [00:02<00:00, 60.02it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  95%|█████████▌| 122/128 [00:02<00:00, 60.06it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 128/128 [00:02<00:00, 54.31it/s]                     
                 all        128        929      0.799      0.702      0.813      0.594
Speed: 0.2ms pre-process, 8.9ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)
Results saved to [1mruns/val/exp226[0m
YOLOv5 🚀 v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Fusing layers... 
YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients, 109.1 GFLOPs

[34m[1mPyTorch:[0m starting from yolov5l.pt with output shape (1, 25200, 85) (89.3 MB)

[34m[1mONNX:[0m starting export with onnx 1.11.0...
[34m[1mONNX:[0m export success, saved as yolov5l.onnx (177.9 MB)

Export complete (6.15s)
Results saved to [1m/home/ubuntu/data/repos/yolov5[0m
Detect:          python detect.py --weights yolov5l.onnx
PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5l.onnx')
Validate:        python val.py --weights yolov5l.onnx
Visualize:       https://netron.app
YOLOv5 🚀 v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Loading yolov5l.onnx for ONNX Runtime inference...
Forcing --batch-size 1 square inference (1,3,640,640) for non-PyTorch models
[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupt: 100%|██████████[0m[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupt: 100%|██████████[0m
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/128 [00:00<?, ?it/s]                                              Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   3%|▎         | 4/128 [00:00<00:03, 34.33it/s]                                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   7%|▋         | 9/128 [00:00<00:03, 38.78it/s]                                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  10%|█         | 13/128 [00:00<00:03, 33.33it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  13%|█▎        | 17/128 [00:00<00:03, 34.98it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  16%|█▋        | 21/128 [00:00<00:02, 36.46it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  20%|██        | 26/128 [00:00<00:02, 39.85it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  24%|██▍       | 31/128 [00:00<00:02, 42.54it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  28%|██▊       | 36/128 [00:00<00:02, 42.54it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  32%|███▏      | 41/128 [00:01<00:02, 42.98it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  36%|███▌      | 46/128 [00:01<00:01, 41.41it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  40%|███▉      | 51/128 [00:01<00:01, 42.96it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  44%|████▍     | 56/128 [00:01<00:01, 43.91it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  48%|████▊     | 61/128 [00:01<00:01, 44.83it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  52%|█████▏    | 66/128 [00:01<00:01, 44.39it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  55%|█████▌    | 71/128 [00:01<00:01, 44.36it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  59%|█████▉    | 76/128 [00:01<00:01, 44.98it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  63%|██████▎   | 81/128 [00:01<00:01, 45.51it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  67%|██████▋   | 86/128 [00:02<00:00, 45.32it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  71%|███████   | 91/128 [00:02<00:00, 45.92it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  75%|███████▌  | 96/128 [00:02<00:00, 46.38it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  79%|███████▉  | 101/128 [00:02<00:00, 46.36it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  83%|████████▎ | 106/128 [00:02<00:00, 45.34it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  87%|████████▋ | 111/128 [00:02<00:00, 45.85it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  91%|█████████ | 116/128 [00:02<00:00, 46.81it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  95%|█████████▍| 121/128 [00:02<00:00, 47.09it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  98%|█████████▊| 126/128 [00:02<00:00, 46.31it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 128/128 [00:02<00:00, 43.64it/s]                     
                 all        128        929      0.799      0.702      0.813      0.594
Speed: 0.2ms pre-process, 13.6ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)
Results saved to [1mruns/val/exp227[0m
WARNING: Benchmark failure for OpenVINO: OpenVINO inference not supported on GPU
YOLOv5 🚀 v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Fusing layers... 
YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients, 109.1 GFLOPs

[34m[1mPyTorch:[0m starting from yolov5l.pt with output shape (1, 25200, 85) (89.3 MB)

[34m[1mONNX:[0m starting export with onnx 1.11.0...
WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
[34m[1mONNX:[0m export success, saved as yolov5l.onnx (177.9 MB)

[34m[1mTensorRT:[0m starting export with TensorRT 8.4.0.6...
[05/08/2022-21:42:05] [TRT] [I] [MemUsageChange] Init CUDA: CPU +348, GPU +0, now: CPU 6894, GPU 4683 (MiB)
[05/08/2022-21:42:06] [TRT] [I] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 6913 MiB, GPU 4683 MiB
[05/08/2022-21:42:06] [TRT] [I] [MemUsageSnapshot] End constructing builder kernel library: CPU 7288 MiB, GPU 4807 MiB
[05/08/2022-21:42:08] [TRT] [I] ----------------------------------------------------------------
[05/08/2022-21:42:08] [TRT] [I] Input filename:   yolov5l.onnx
[05/08/2022-21:42:08] [TRT] [I] ONNX IR version:  0.0.7
[05/08/2022-21:42:08] [TRT] [I] Opset version:    13
[05/08/2022-21:42:08] [TRT] [I] Producer name:    pytorch
[05/08/2022-21:42:08] [TRT] [I] Producer version: 1.10
[05/08/2022-21:42:08] [TRT] [I] Domain:           
[05/08/2022-21:42:08] [TRT] [I] Model version:    0
[05/08/2022-21:42:08] [TRT] [I] Doc string:       
[05/08/2022-21:42:08] [TRT] [I] ----------------------------------------------------------------
[05/08/2022-21:42:08] [TRT] [W] onnx2trt_utils.cpp:365: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[34m[1mTensorRT:[0m Network Description:
[34m[1mTensorRT:[0m	input "images" with shape (1, 3, 640, 640) and dtype DataType.FLOAT
[34m[1mTensorRT:[0m	output "output" with shape (1, 25200, 85) and dtype DataType.FLOAT
[34m[1mTensorRT:[0m building FP16 engine in yolov5l.engine
[05/08/2022-21:42:09] [TRT] [W] TensorRT was linked against cuBLAS/cuBLAS LT 11.8.0 but loaded cuBLAS/cuBLAS LT 110.9.2
[05/08/2022-21:42:09] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 7481, GPU 4815 (MiB)
[05/08/2022-21:42:09] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 7482, GPU 4825 (MiB)
[05/08/2022-21:42:09] [TRT] [W] TensorRT was linked against cuDNN 8.3.2 but loaded cuDNN 8.1.1
[05/08/2022-21:42:09] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/08/2022-21:43:20] [TRT] [I] Some tactics do not have sufficient workspace memory to run. Increasing workspace size will enable more tactics, please check verbose output for requested sizes.
[05/08/2022-21:51:28] [TRT] [I] Detected 1 inputs and 4 output network tensors.
[05/08/2022-21:51:32] [TRT] [I] Total Host Persistent Memory: 277888
[05/08/2022-21:51:32] [TRT] [I] Total Device Persistent Memory: 1799168
[05/08/2022-21:51:32] [TRT] [I] Total Scratch Memory: 0
[05/08/2022-21:51:32] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 103 MiB, GPU 2236 MiB
[05/08/2022-21:51:32] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 29.8148ms to assign 9 blocks to 163 nodes requiring 34150404 bytes.
[05/08/2022-21:51:32] [TRT] [I] Total Activation Memory: 34150404
[05/08/2022-21:51:32] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +89, GPU +90, now: CPU 89, GPU 90 (MiB)
[34m[1mTensorRT:[0m export success, saved as yolov5l.engine (92.3 MB)

Export complete (572.81s)
Results saved to [1m/home/ubuntu/data/repos/yolov5[0m
Detect:          python detect.py --weights yolov5l.engine
PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5l.engine')
Validate:        python val.py --weights yolov5l.engine
Visualize:       https://netron.app
YOLOv5 🚀 v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Loading yolov5l.engine for TensorRT inference...
[05/08/2022-21:51:32] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.

[05/08/2022-21:51:32] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 7489, GPU 4809 (MiB)
[05/08/2022-21:51:33] [TRT] [I] Loaded engine size: 92 MiB
[05/08/2022-21:51:33] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +90, now: CPU 0, GPU 90 (MiB)
[05/08/2022-21:51:33] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +34, now: CPU 0, GPU 124 (MiB)
[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupt: 100%|██████████[0m[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupt: 100%|██████████[0m
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/128 [00:00<?, ?it/s]                                              Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   4%|▍         | 5/128 [00:00<00:02, 48.19it/s]                                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   9%|▉         | 12/128 [00:00<00:01, 59.42it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  15%|█▍        | 19/128 [00:00<00:01, 64.09it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  23%|██▎       | 29/128 [00:00<00:01, 75.98it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  30%|██▉       | 38/128 [00:00<00:01, 80.12it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  38%|███▊      | 48/128 [00:00<00:00, 84.82it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  45%|████▍     | 57/128 [00:00<00:00, 86.14it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  52%|█████▏    | 67/128 [00:00<00:00, 88.04it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  60%|██████    | 77/128 [00:00<00:00, 90.21it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  68%|██████▊   | 87/128 [00:01<00:00, 89.18it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  76%|███████▌  | 97/128 [00:01<00:00, 91.87it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  84%|████████▎ | 107/128 [00:01<00:00, 87.79it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  91%|█████████▏| 117/128 [00:01<00:00, 88.91it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  99%|█████████▉| 127/128 [00:01<00:00, 89.17it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 128/128 [00:01<00:00, 84.55it/s]                     
                 all        128        929      0.801      0.702      0.812      0.595
Speed: 0.2ms pre-process, 2.6ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)
Results saved to [1mruns/val/exp228[0m
WARNING: Benchmark failure for CoreML: CoreML inference not supported on GPU
YOLOv5 🚀 v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Fusing layers... 
YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients, 109.1 GFLOPs

[34m[1mPyTorch:[0m starting from yolov5l.pt with output shape (1, 25200, 85) (89.3 MB)

[34m[1mTensorFlow SavedModel:[0m starting export with tensorflow 2.8.0...

                 from  n    params  module                                  arguments                     
2022-05-08 21:51:52.490153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:52.494713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:52.495007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:52.495803: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-08 21:51:52.497940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:52.498239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:52.498517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:52.499179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:52.499473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:52.499752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:52.500127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 42541 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:06:00.0, compute capability: 8.6
  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              
  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  2                -1  1    156928  models.common.C3                        [128, 128, 3]                 
  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  4                -1  1   1118208  models.common.C3                        [256, 256, 6]                 
  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              
  6                -1  1   6433792  models.common.C3                        [512, 512, 9]                 
  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             
  8                -1  1   9971712  models.common.C3                        [1024, 1024, 3]               
  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               
 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 12           [-1, 6]  1         0  models.common.Concat                    [1]                           
 13                -1  1   2757632  models.common.C3                        [1024, 512, 3, False]         
 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 16           [-1, 4]  1         0  models.common.Concat                    [1]                           
 17                -1  1    690688  models.common.C3                        [512, 256, 3, False]          
 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              
 19          [-1, 14]  1         0  models.common.Concat                    [1]                           
 20                -1  1   2495488  models.common.C3                        [512, 512, 3, False]          
 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              
 22          [-1, 10]  1         0  models.common.Concat                    [1]                           
 23                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        
 24      [17, 20, 23]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024], [640, 640]]
2022-05-08 21:51:53.547305: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101
2022-05-08 21:51:53.689450: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(1, 640, 640, 3)]   0           []                               
                                                                                                  
 tf_conv (TFConv)               (1, 320, 320, 64)    6976        ['input_1[0][0]']                
                                                                                                  
 tf_conv_1 (TFConv)             (1, 160, 160, 128)   73856       ['tf_conv[0][0]']                
                                                                                                  
 tfc3 (TFC3)                    (1, 160, 160, 128)   156288      ['tf_conv_1[0][0]']              
                                                                                                  
 tf_conv_11 (TFConv)            (1, 80, 80, 256)     295168      ['tfc3[0][0]']                   
                                                                                                  
 tfc3_1 (TFC3)                  (1, 80, 80, 256)     1116160     ['tf_conv_11[0][0]']             
                                                                                                  
 tf_conv_27 (TFConv)            (1, 40, 40, 512)     1180160     ['tfc3_1[0][0]']                 
                                                                                                  
 tfc3_2 (TFC3)                  (1, 40, 40, 512)     6428160     ['tf_conv_27[0][0]']             
                                                                                                  
 tf_conv_49 (TFConv)            (1, 20, 20, 1024)    4719616     ['tfc3_2[0][0]']                 
                                                                                                  
 tfc3_3 (TFC3)                  (1, 20, 20, 1024)    9966592     ['tf_conv_49[0][0]']             
                                                                                                  
 tfsppf (TFSPPF)                (1, 20, 20, 1024)    2622976     ['tfc3_3[0][0]']                 
                                                                                                  
 tf_conv_61 (TFConv)            (1, 20, 20, 512)     524800      ['tfsppf[0][0]']                 
                                                                                                  
 tf_upsample (TFUpsample)       (1, 40, 40, 512)     0           ['tf_conv_61[0][0]']             
                                                                                                  
 tf_concat (TFConcat)           (1, 40, 40, 1024)    0           ['tf_upsample[0][0]',            
                                                                  'tfc3_2[0][0]']                 
                                                                                                  
 tfc3_4 (TFC3)                  (1, 40, 40, 512)     2755072     ['tf_concat[0][0]']              
                                                                                                  
 tf_conv_71 (TFConv)            (1, 40, 40, 256)     131328      ['tfc3_4[0][0]']                 
                                                                                                  
 tf_upsample_1 (TFUpsample)     (1, 80, 80, 256)     0           ['tf_conv_71[0][0]']             
                                                                                                  
 tf_concat_1 (TFConcat)         (1, 80, 80, 512)     0           ['tf_upsample_1[0][0]',          
                                                                  'tfc3_1[0][0]']                 
                                                                                                  
 tfc3_5 (TFC3)                  (1, 80, 80, 256)     689408      ['tf_concat_1[0][0]']            
                                                                                                  
 tf_conv_81 (TFConv)            (1, 40, 40, 256)     590080      ['tfc3_5[0][0]']                 
                                                                                                  
 tf_concat_2 (TFConcat)         (1, 40, 40, 512)     0           ['tf_conv_81[0][0]',             
                                                                  'tf_conv_71[0][0]']             
                                                                                                  
 tfc3_6 (TFC3)                  (1, 40, 40, 512)     2492928     ['tf_concat_2[0][0]']            
                                                                                                  
 tf_conv_91 (TFConv)            (1, 20, 20, 512)     2359808     ['tfc3_6[0][0]']                 
                                                                                                  
 tf_concat_3 (TFConcat)         (1, 20, 20, 1024)    0           ['tf_conv_91[0][0]',             
                                                                  'tf_conv_61[0][0]']             
                                                                                                  
 tfc3_7 (TFC3)                  (1, 20, 20, 1024)    9966592     ['tf_concat_3[0][0]']            
                                                                                                  
 tf_detect (TFDetect)           ((1, 25200, 85),     457725      ['tfc3_5[0][0]',                 
                                 [(1, 6400, 3, 85),               'tfc3_6[0][0]',                 
                                 (1, 1600, 3, 85),                'tfc3_7[0][0]']                 
                                 (1, 400, 3, 85)])                                                
                                                                                                  
==================================================================================================
Total params: 46,533,693
Trainable params: 0
Non-trainable params: 46,533,693
__________________________________________________________________________________________________
2022-05-08 21:51:57.868547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:57.868803: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-05-08 21:51:57.868993: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
2022-05-08 21:51:57.869795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:57.870020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:57.870217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:57.870472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:57.870680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:51:57.870834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 42541 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:06:00.0, compute capability: 8.6
2022-05-08 21:51:57.893496: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize
  function_optimizer: function_optimizer did nothing. time = 0.184ms.
  function_optimizer: function_optimizer did nothing. time = 0.006ms.

2022-05-08 21:52:02.058251: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
Assets written to: yolov5l_saved_model/assets
[34m[1mTensorFlow SavedModel:[0m export success, saved as yolov5l_saved_model (177.9 MB)

Export complete (27.58s)
Results saved to [1m/home/ubuntu/data/repos/yolov5[0m
Detect:          python detect.py --weights yolov5l_saved_model
PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5l_saved_model')
Validate:        python val.py --weights yolov5l_saved_model
Visualize:       https://netron.app
YOLOv5 🚀 v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Loading yolov5l_saved_model for TensorFlow SavedModel inference...
Importing a function (__inference_pruned_10948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
Forcing --batch-size 1 square inference (1,3,640,640) for non-PyTorch models
[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupt: 100%|██████████[0m[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupt: 100%|██████████[0m
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/128 [00:00<?, ?it/s]                                              Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   2%|▏         | 2/128 [00:00<00:06, 19.19it/s]                                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   3%|▎         | 4/128 [00:00<00:07, 17.05it/s]                                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   5%|▌         | 7/128 [00:00<00:05, 21.05it/s]                                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   8%|▊         | 10/128 [00:00<00:05, 22.31it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  10%|█         | 13/128 [00:00<00:04, 23.09it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  12%|█▎        | 16/128 [00:00<00:04, 23.09it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  15%|█▍        | 19/128 [00:00<00:04, 23.09it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  17%|█▋        | 22/128 [00:01<00:04, 21.54it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  20%|█▉        | 25/128 [00:01<00:04, 22.66it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  22%|██▏       | 28/128 [00:01<00:04, 22.55it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  24%|██▍       | 31/128 [00:01<00:04, 20.86it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  27%|██▋       | 34/128 [00:01<00:04, 21.84it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  29%|██▉       | 37/128 [00:01<00:04, 21.16it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  31%|███▏      | 40/128 [00:01<00:03, 22.10it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  34%|███▎      | 43/128 [00:01<00:03, 22.29it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  36%|███▌      | 46/128 [00:02<00:03, 22.72it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  38%|███▊      | 49/128 [00:02<00:03, 22.40it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  41%|████      | 52/128 [00:02<00:03, 22.59it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  43%|████▎     | 55/128 [00:02<00:03, 22.12it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  45%|████▌     | 58/128 [00:02<00:03, 22.21it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  48%|████▊     | 61/128 [00:02<00:02, 22.42it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  50%|█████     | 64/128 [00:02<00:02, 23.21it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  52%|█████▏    | 67/128 [00:03<00:02, 23.04it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  55%|█████▍    | 70/128 [00:03<00:02, 21.51it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  57%|█████▋    | 73/128 [00:03<00:02, 21.28it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  59%|█████▉    | 76/128 [00:03<00:02, 21.72it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  62%|██████▏   | 79/128 [00:03<00:02, 21.40it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  64%|██████▍   | 82/128 [00:03<00:02, 22.62it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  66%|██████▋   | 85/128 [00:03<00:01, 22.03it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  69%|██████▉   | 88/128 [00:04<00:01, 21.30it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  71%|███████   | 91/128 [00:04<00:01, 21.28it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  73%|███████▎  | 94/128 [00:04<00:01, 21.93it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  76%|███████▌  | 97/128 [00:04<00:01, 21.87it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  78%|███████▊  | 100/128 [00:04<00:01, 22.08it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  80%|████████  | 103/128 [00:04<00:01, 21.34it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  83%|████████▎ | 106/128 [00:04<00:01, 20.74it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  85%|████████▌ | 109/128 [00:04<00:00, 20.88it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  88%|████████▊ | 112/128 [00:05<00:00, 20.42it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  90%|████████▉ | 115/128 [00:05<00:00, 20.41it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  92%|█████████▏| 118/128 [00:05<00:00, 21.09it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  95%|█████████▍| 121/128 [00:05<00:00, 21.80it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  97%|█████████▋| 124/128 [00:05<00:00, 21.57it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  99%|█████████▉| 127/128 [00:05<00:00, 21.60it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 128/128 [00:05<00:00, 21.74it/s]                     
                 all        128        929      0.799      0.702      0.813      0.594
Speed: 0.2ms pre-process, 28.9ms inference, 1.7ms NMS per image at shape (1, 3, 640, 640)
Results saved to [1mruns/val/exp229[0m
YOLOv5 🚀 v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Fusing layers... 
YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients, 109.1 GFLOPs

[34m[1mPyTorch:[0m starting from yolov5l.pt with output shape (1, 25200, 85) (89.3 MB)

[34m[1mTensorFlow SavedModel:[0m starting export with tensorflow 2.8.0...

                 from  n    params  module                                  arguments                     
  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              
  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  2                -1  1    156928  models.common.C3                        [128, 128, 3]                 
  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  4                -1  1   1118208  models.common.C3                        [256, 256, 6]                 
  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              
  6                -1  1   6433792  models.common.C3                        [512, 512, 9]                 
  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             
  8                -1  1   9971712  models.common.C3                        [1024, 1024, 3]               
  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               
 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 12           [-1, 6]  1         0  models.common.Concat                    [1]                           
 13                -1  1   2757632  models.common.C3                        [1024, 512, 3, False]         
 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 16           [-1, 4]  1         0  models.common.Concat                    [1]                           
 17                -1  1    690688  models.common.C3                        [512, 256, 3, False]          
 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              
 19          [-1, 14]  1         0  models.common.Concat                    [1]                           
 20                -1  1   2495488  models.common.C3                        [512, 512, 3, False]          
 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              
 22          [-1, 10]  1         0  models.common.Concat                    [1]                           
 23                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        
 24      [17, 20, 23]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024], [640, 640]]
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_2 (InputLayer)           [(1, 640, 640, 3)]   0           []                               
                                                                                                  
 tf_conv_101 (TFConv)           (1, 320, 320, 64)    6976        ['input_2[0][0]']                
                                                                                                  
 tf_conv_102 (TFConv)           (1, 160, 160, 128)   73856       ['tf_conv_101[0][0]']            
                                                                                                  
 tfc3_8 (TFC3)                  (1, 160, 160, 128)   156288      ['tf_conv_102[0][0]']            
                                                                                                  
 tf_conv_112 (TFConv)           (1, 80, 80, 256)     295168      ['tfc3_8[0][0]']                 
                                                                                                  
 tfc3_9 (TFC3)                  (1, 80, 80, 256)     1116160     ['tf_conv_112[0][0]']            
                                                                                                  
 tf_conv_128 (TFConv)           (1, 40, 40, 512)     1180160     ['tfc3_9[0][0]']                 
                                                                                                  
 tfc3_10 (TFC3)                 (1, 40, 40, 512)     6428160     ['tf_conv_128[0][0]']            
                                                                                                  
 tf_conv_150 (TFConv)           (1, 20, 20, 1024)    4719616     ['tfc3_10[0][0]']                
                                                                                                  
 tfc3_11 (TFC3)                 (1, 20, 20, 1024)    9966592     ['tf_conv_150[0][0]']            
                                                                                                  
 tfsppf_1 (TFSPPF)              (1, 20, 20, 1024)    2622976     ['tfc3_11[0][0]']                
                                                                                                  
 tf_conv_162 (TFConv)           (1, 20, 20, 512)     524800      ['tfsppf_1[0][0]']               
                                                                                                  
 tf_upsample_2 (TFUpsample)     (1, 40, 40, 512)     0           ['tf_conv_162[0][0]']            
                                                                                                  
 tf_concat_4 (TFConcat)         (1, 40, 40, 1024)    0           ['tf_upsample_2[0][0]',          
                                                                  'tfc3_10[0][0]']                
                                                                                                  
 tfc3_12 (TFC3)                 (1, 40, 40, 512)     2755072     ['tf_concat_4[0][0]']            
                                                                                                  
 tf_conv_172 (TFConv)           (1, 40, 40, 256)     131328      ['tfc3_12[0][0]']                
                                                                                                  
 tf_upsample_3 (TFUpsample)     (1, 80, 80, 256)     0           ['tf_conv_172[0][0]']            
                                                                                                  
 tf_concat_5 (TFConcat)         (1, 80, 80, 512)     0           ['tf_upsample_3[0][0]',          
                                                                  'tfc3_9[0][0]']                 
                                                                                                  
 tfc3_13 (TFC3)                 (1, 80, 80, 256)     689408      ['tf_concat_5[0][0]']            
                                                                                                  
 tf_conv_182 (TFConv)           (1, 40, 40, 256)     590080      ['tfc3_13[0][0]']                
                                                                                                  
 tf_concat_6 (TFConcat)         (1, 40, 40, 512)     0           ['tf_conv_182[0][0]',            
                                                                  'tf_conv_172[0][0]']            
                                                                                                  
 tfc3_14 (TFC3)                 (1, 40, 40, 512)     2492928     ['tf_concat_6[0][0]']            
                                                                                                  
 tf_conv_192 (TFConv)           (1, 20, 20, 512)     2359808     ['tfc3_14[0][0]']                
                                                                                                  
 tf_concat_7 (TFConcat)         (1, 20, 20, 1024)    0           ['tf_conv_192[0][0]',            
                                                                  'tf_conv_162[0][0]']            
                                                                                                  
 tfc3_15 (TFC3)                 (1, 20, 20, 1024)    9966592     ['tf_concat_7[0][0]']            
                                                                                                  
 tf_detect_1 (TFDetect)         ((1, 25200, 85),     457725      ['tfc3_13[0][0]',                
                                 [(1, 6400, 3, 85),               'tfc3_14[0][0]',                
                                 (1, 1600, 3, 85),                'tfc3_15[0][0]']                
                                 (1, 400, 3, 85)])                                                
                                                                                                  
==================================================================================================
Total params: 46,533,693
Trainable params: 0
Non-trainable params: 46,533,693
__________________________________________________________________________________________________
2022-05-08 21:52:18.940268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:52:18.940522: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-05-08 21:52:18.940667: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
2022-05-08 21:52:18.941172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:52:18.941426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:52:18.941626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:52:18.941877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:52:18.942076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:52:18.942223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 42541 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:06:00.0, compute capability: 8.6
2022-05-08 21:52:18.962156: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize
  function_optimizer: function_optimizer did nothing. time = 0.016ms.
  function_optimizer: function_optimizer did nothing. time = 0.004ms.

Assets written to: yolov5l_saved_model/assets
[34m[1mTensorFlow SavedModel:[0m export success, saved as yolov5l_saved_model (177.9 MB)

[34m[1mTensorFlow GraphDef:[0m starting export with tensorflow 2.8.0...
2022-05-08 21:52:25.590820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:52:25.591113: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-05-08 21:52:25.591264: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
2022-05-08 21:52:25.591747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:52:25.591960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:52:25.592150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:52:25.592398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:52:25.592595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:52:25.592930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 42541 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:06:00.0, compute capability: 8.6
2022-05-08 21:52:25.615018: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize
  function_optimizer: function_optimizer did nothing. time = 0.021ms.
  function_optimizer: function_optimizer did nothing. time = 0.004ms.

[34m[1mTensorFlow GraphDef:[0m export success, saved as yolov5l.pb (177.9 MB)

Export complete (15.36s)
Results saved to [1m/home/ubuntu/data/repos/yolov5[0m
Detect:          python detect.py --weights yolov5l.pb
PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5l.pb')
Validate:        python val.py --weights yolov5l.pb
Visualize:       https://netron.app
YOLOv5 🚀 v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Loading yolov5l.pb for TensorFlow GraphDef inference...
Forcing --batch-size 1 square inference (1,3,640,640) for non-PyTorch models
[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupt: 100%|██████████[0m[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupt: 100%|██████████[0m
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/128 [00:00<?, ?it/s]                                              Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   2%|▏         | 3/128 [00:00<00:04, 28.06it/s]                                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   5%|▍         | 6/128 [00:00<00:04, 25.53it/s]                                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   7%|▋         | 9/128 [00:00<00:04, 25.17it/s]                                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  10%|█         | 13/128 [00:00<00:04, 27.04it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  12%|█▎        | 16/128 [00:00<00:04, 27.77it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  15%|█▍        | 19/128 [00:00<00:03, 27.54it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  17%|█▋        | 22/128 [00:00<00:04, 26.13it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  20%|█▉        | 25/128 [00:00<00:03, 27.13it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  22%|██▏       | 28/128 [00:01<00:03, 25.48it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  24%|██▍       | 31/128 [00:01<00:03, 25.96it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  27%|██▋       | 34/128 [00:01<00:03, 26.56it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  29%|██▉       | 37/128 [00:01<00:03, 24.82it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  31%|███▏      | 40/128 [00:01<00:03, 24.10it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  34%|███▎      | 43/128 [00:01<00:03, 24.88it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  36%|███▌      | 46/128 [00:01<00:03, 24.17it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  38%|███▊      | 49/128 [00:01<00:03, 25.02it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  41%|████      | 52/128 [00:02<00:03, 24.73it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  43%|████▎     | 55/128 [00:02<00:02, 25.94it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  45%|████▌     | 58/128 [00:02<00:02, 26.48it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  48%|████▊     | 61/128 [00:02<00:02, 26.45it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  50%|█████     | 64/128 [00:02<00:02, 25.76it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  52%|█████▏    | 67/128 [00:02<00:02, 25.92it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  55%|█████▍    | 70/128 [00:02<00:02, 25.52it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  57%|█████▋    | 73/128 [00:02<00:02, 25.59it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  59%|█████▉    | 76/128 [00:02<00:02, 25.02it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  62%|██████▏   | 79/128 [00:03<00:01, 25.40it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  65%|██████▍   | 83/128 [00:03<00:01, 27.42it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  68%|██████▊   | 87/128 [00:03<00:01, 29.25it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  71%|███████   | 91/128 [00:03<00:01, 30.72it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  74%|███████▍  | 95/128 [00:03<00:01, 30.54it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  77%|███████▋  | 99/128 [00:03<00:00, 31.22it/s]                                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  80%|████████  | 103/128 [00:03<00:00, 30.25it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  84%|████████▎ | 107/128 [00:03<00:00, 30.12it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  87%|████████▋ | 111/128 [00:04<00:00, 31.14it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  90%|████████▉ | 115/128 [00:04<00:00, 31.98it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  93%|█████████▎| 119/128 [00:04<00:00, 32.32it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  96%|█████████▌| 123/128 [00:04<00:00, 32.49it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  99%|█████████▉| 127/128 [00:04<00:00, 31.97it/s]                                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 128/128 [00:04<00:00, 27.80it/s]                     
                 all        128        929      0.799      0.702      0.813      0.594
Speed: 0.2ms pre-process, 22.2ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)
Results saved to [1mruns/val/exp230[0m
WARNING: Benchmark failure for TensorFlow Lite: TensorFlow Lite inference not supported on GPU
WARNING: Benchmark failure for TensorFlow Edge TPU: Edge TPU not supported
WARNING: Benchmark failure for TensorFlow.js: TF.js not supported


[34m[1mbenchmarks: [0mweights=yolov5l.pt, imgsz=640, batch_size=1, data=/home/ubuntu/data/repos/yolov5/data/coco128.yaml, device=0, half=False, test=False, pt_only=False
Checking setup...
[2KYOLOv5 🚀 v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Benchmarks complete (669.27s)
                   Format  mAP@0.5:0.95  Inference time (ms)
0                 PyTorch        0.5944                12.35
1             TorchScript        0.5944                 8.89
2                    ONNX        0.5944                13.59
3                OpenVINO           NaN                  NaN
4                TensorRT        0.5950                 2.60
5                  CoreML           NaN                  NaN
6   TensorFlow SavedModel        0.5944                28.91
7     TensorFlow GraphDef        0.5944                22.15
8         TensorFlow Lite           NaN                  NaN
9     TensorFlow Edge TPU           NaN                  NaN
10          TensorFlow.js           NaN                  NaN
[2KSetup complete ✅ (14 CPUs, 98.2 GB RAM, 31.7/992.3 GB disk)
