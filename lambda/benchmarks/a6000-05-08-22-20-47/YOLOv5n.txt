[34m[1mbenchmarks: [0mweights=yolov5n.pt, imgsz=640, batch_size=1, data=/home/ubuntu/data/repos/yolov5/data/coco128.yaml, device=0, half=False, test=False, pt_only=False
YOLOv5 ðŸš€ v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

YOLOv5 ðŸš€ v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Fusing layers... 
YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs
[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 12[0m[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 12[0m
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|                         Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   5%|â–                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  10%|â–ˆ                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  16%|â–ˆâ–Œ                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  21%|â–ˆâ–ˆ                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  27%|â–ˆâ–ˆâ–‹                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  33%|â–ˆâ–ˆâ–ˆâ–Ž                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  38%|â–ˆâ–ˆâ–ˆâ–Š                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                  Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                 all        128        929      0.737       0.45      0.545      0.342
Speed: 0.2ms pre-process, 7.0ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)
Results saved to [1mruns/val/exp213[0m
YOLOv5 ðŸš€ v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Fusing layers... 
YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs

[34m[1mPyTorch:[0m starting from yolov5n.pt with output shape (1, 25200, 85) (3.9 MB)

[34m[1mTorchScript:[0m starting export with torch 1.10.1+cu113...
[34m[1mTorchScript:[0m export success, saved as yolov5n.torchscript (7.6 MB)

Export complete (1.32s)
Results saved to [1m/home/ubuntu/data/repos/yolov5[0m
Detect:          python detect.py --weights yolov5n.torchscript
PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5n.torchscript')
Validate:        python val.py --weights yolov5n.torchscript
Visualize:       https://netron.app
YOLOv5 ðŸš€ v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Loading yolov5n.torchscript for TorchScript inference...
[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 12[0m[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 12[0m
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|                         Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   5%|â–                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  10%|â–ˆ                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  15%|â–ˆâ–                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  21%|â–ˆâ–ˆ                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  27%|â–ˆâ–ˆâ–‹                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  34%|â–ˆâ–ˆâ–ˆâ–Ž                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  39%|â–ˆâ–ˆâ–ˆâ–‰                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                 all        128        929      0.737       0.45      0.545      0.342
Speed: 0.2ms pre-process, 5.1ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)
Results saved to [1mruns/val/exp214[0m
YOLOv5 ðŸš€ v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Fusing layers... 
YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs

[34m[1mPyTorch:[0m starting from yolov5n.pt with output shape (1, 25200, 85) (3.9 MB)

[34m[1mONNX:[0m starting export with onnx 1.11.0...
[34m[1mONNX:[0m export success, saved as yolov5n.onnx (7.5 MB)

Export complete (2.51s)
Results saved to [1m/home/ubuntu/data/repos/yolov5[0m
Detect:          python detect.py --weights yolov5n.onnx
PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5n.onnx')
Validate:        python val.py --weights yolov5n.onnx
Visualize:       https://netron.app
YOLOv5 ðŸš€ v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Loading yolov5n.onnx for ONNX Runtime inference...
Forcing --batch-size 1 square inference (1,3,640,640) for non-PyTorch models
[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 12[0m[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 12[0m
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|                         Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   5%|â–                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   9%|â–‰                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  14%|â–ˆâ–                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  19%|â–ˆâ–‰                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  24%|â–ˆâ–ˆâ–                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  29%|â–ˆâ–ˆâ–‰                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  34%|â–ˆâ–ˆâ–ˆâ–Ž                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  39%|â–ˆâ–ˆâ–ˆâ–‰                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                 all        128        929      0.738       0.45      0.545      0.342
Speed: 0.2ms pre-process, 7.1ms inference, 1.6ms NMS per image at shape (1, 3, 640, 640)
Results saved to [1mruns/val/exp215[0m
WARNING: Benchmark failure for OpenVINO: OpenVINO inference not supported on GPU
YOLOv5 ðŸš€ v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Fusing layers... 
YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs

[34m[1mPyTorch:[0m starting from yolov5n.pt with output shape (1, 25200, 85) (3.9 MB)

[34m[1mONNX:[0m starting export with onnx 1.11.0...
WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.
[34m[1mONNX:[0m export success, saved as yolov5n.onnx (7.5 MB)

[34m[1mTensorRT:[0m starting export with TensorRT 8.4.0.6...
[05/08/2022-21:20:15] [TRT] [I] [MemUsageChange] Init CUDA: CPU +348, GPU +0, now: CPU 6788, GPU 3537 (MiB)
[05/08/2022-21:20:16] [TRT] [I] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 6807 MiB, GPU 3537 MiB
[05/08/2022-21:20:16] [TRT] [I] [MemUsageSnapshot] End constructing builder kernel library: CPU 7182 MiB, GPU 3661 MiB
[05/08/2022-21:20:16] [TRT] [I] ----------------------------------------------------------------
[05/08/2022-21:20:16] [TRT] [I] Input filename:   yolov5n.onnx
[05/08/2022-21:20:16] [TRT] [I] ONNX IR version:  0.0.7
[05/08/2022-21:20:16] [TRT] [I] Opset version:    13
[05/08/2022-21:20:16] [TRT] [I] Producer name:    pytorch
[05/08/2022-21:20:16] [TRT] [I] Producer version: 1.10
[05/08/2022-21:20:16] [TRT] [I] Domain:           
[05/08/2022-21:20:16] [TRT] [I] Model version:    0
[05/08/2022-21:20:16] [TRT] [I] Doc string:       
[05/08/2022-21:20:16] [TRT] [I] ----------------------------------------------------------------
[05/08/2022-21:20:16] [TRT] [W] onnx2trt_utils.cpp:365: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[34m[1mTensorRT:[0m Network Description:
[34m[1mTensorRT:[0m	input "images" with shape (1, 3, 640, 640) and dtype DataType.FLOAT
[34m[1mTensorRT:[0m	output "output" with shape (1, 25200, 85) and dtype DataType.FLOAT
[34m[1mTensorRT:[0m building FP16 engine in yolov5n.engine
[05/08/2022-21:20:17] [TRT] [W] TensorRT was linked against cuBLAS/cuBLAS LT 11.8.0 but loaded cuBLAS/cuBLAS LT 110.9.2
[05/08/2022-21:20:17] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 7192, GPU 3669 (MiB)
[05/08/2022-21:20:17] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 7192, GPU 3677 (MiB)
[05/08/2022-21:20:17] [TRT] [W] TensorRT was linked against cuDNN 8.3.2 but loaded cuDNN 8.1.1
[05/08/2022-21:20:17] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/08/2022-21:28:48] [TRT] [I] Detected 1 inputs and 4 output network tensors.
[05/08/2022-21:28:52] [TRT] [I] Total Host Persistent Memory: 151120
[05/08/2022-21:28:52] [TRT] [I] Total Device Persistent Memory: 97280
[05/08/2022-21:28:52] [TRT] [I] Total Scratch Memory: 0
[05/08/2022-21:28:52] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 4 MiB, GPU 2101 MiB
[05/08/2022-21:28:52] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 15.1511ms to assign 8 blocks to 106 nodes requiring 12665860 bytes.
[05/08/2022-21:28:52] [TRT] [I] Total Activation Memory: 12665860
[05/08/2022-21:28:52] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +3, GPU +4, now: CPU 3, GPU 4 (MiB)
[34m[1mTensorRT:[0m export success, saved as yolov5n.engine (6.3 MB)

Export complete (519.79s)
Results saved to [1m/home/ubuntu/data/repos/yolov5[0m
Detect:          python detect.py --weights yolov5n.engine
PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5n.engine')
Validate:        python val.py --weights yolov5n.engine
Visualize:       https://netron.app
YOLOv5 ðŸš€ v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Loading yolov5n.engine for TensorRT inference...
[05/08/2022-21:28:53] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.

[05/08/2022-21:28:53] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 7212, GPU 3661 (MiB)
[05/08/2022-21:28:53] [TRT] [I] Loaded engine size: 6 MiB
[05/08/2022-21:28:53] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +3, now: CPU 0, GPU 3 (MiB)
[05/08/2022-21:28:53] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +13, now: CPU 0, GPU 16 (MiB)
[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 12[0m[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 12[0m
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|                         Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   5%|â–                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   9%|â–‰                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  14%|â–ˆâ–                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  19%|â–ˆâ–‰                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  27%|â–ˆâ–ˆâ–‹                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  35%|â–ˆâ–ˆâ–ˆâ–Œ                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                 all        128        929      0.738      0.449      0.545      0.342
Speed: 0.2ms pre-process, 0.8ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)
Results saved to [1mruns/val/exp216[0m
WARNING: Benchmark failure for CoreML: CoreML inference not supported on GPU
YOLOv5 ðŸš€ v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Fusing layers... 
YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs

[34m[1mPyTorch:[0m starting from yolov5n.pt with output shape (1, 25200, 85) (3.9 MB)

[34m[1mTensorFlow SavedModel:[0m starting export with tensorflow 2.8.0...

                 from  n    params  module                                  arguments                     
2022-05-08 21:29:19.972315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:19.978225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:19.978539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:19.979464: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-08 21:29:19.981204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:19.981511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:19.981770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:20.530980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:20.531262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:20.531474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:20.531819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43317 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:06:00.0, compute capability: 8.6
  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              
  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                
  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   
  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                
  4                -1  1     29184  models.common.C3                        [64, 64, 2]                   
  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  6                -1  1    156928  models.common.C3                        [128, 128, 3]                 
  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 
  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 
 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 12           [-1, 6]  1         0  models.common.Concat                    [1]                           
 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          
 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 16           [-1, 4]  1         0  models.common.Concat                    [1]                           
 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           
 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                
 19          [-1, 14]  1         0  models.common.Concat                    [1]                           
 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]          
 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              
 22          [-1, 10]  1         0  models.common.Concat                    [1]                           
 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]          
 24      [17, 20, 23]  1    115005  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256], [640, 640]]
2022-05-08 21:29:21.166137: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101
2022-05-08 21:29:21.298476: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(1, 640, 640, 3)]   0           []                               
                                                                                                  
 tf_conv (TFConv)               (1, 320, 320, 16)    1744        ['input_1[0][0]']                
                                                                                                  
 tf_conv_1 (TFConv)             (1, 160, 160, 32)    4640        ['tf_conv[0][0]']                
                                                                                                  
 tfc3 (TFC3)                    (1, 160, 160, 32)    4704        ['tf_conv_1[0][0]']              
                                                                                                  
 tf_conv_7 (TFConv)             (1, 80, 80, 64)      18496       ['tfc3[0][0]']                   
                                                                                                  
 tfc3_1 (TFC3)                  (1, 80, 80, 64)      28928       ['tf_conv_7[0][0]']              
                                                                                                  
 tf_conv_15 (TFConv)            (1, 40, 40, 128)     73856       ['tfc3_1[0][0]']                 
                                                                                                  
 tfc3_2 (TFC3)                  (1, 40, 40, 128)     156288      ['tf_conv_15[0][0]']             
                                                                                                  
 tf_conv_25 (TFConv)            (1, 20, 20, 256)     295168      ['tfc3_2[0][0]']                 
                                                                                                  
 tfc3_3 (TFC3)                  (1, 20, 20, 256)     295680      ['tf_conv_25[0][0]']             
                                                                                                  
 tfsppf (TFSPPF)                (1, 20, 20, 256)     164224      ['tfc3_3[0][0]']                 
                                                                                                  
 tf_conv_33 (TFConv)            (1, 20, 20, 128)     32896       ['tfsppf[0][0]']                 
                                                                                                  
 tf_upsample (TFUpsample)       (1, 40, 40, 128)     0           ['tf_conv_33[0][0]']             
                                                                                                  
 tf_concat (TFConcat)           (1, 40, 40, 256)     0           ['tf_upsample[0][0]',            
                                                                  'tfc3_2[0][0]']                 
                                                                                                  
 tfc3_4 (TFC3)                  (1, 40, 40, 128)     90496       ['tf_concat[0][0]']              
                                                                                                  
 tf_conv_39 (TFConv)            (1, 40, 40, 64)      8256        ['tfc3_4[0][0]']                 
                                                                                                  
 tf_upsample_1 (TFUpsample)     (1, 80, 80, 64)      0           ['tf_conv_39[0][0]']             
                                                                                                  
 tf_concat_1 (TFConcat)         (1, 80, 80, 128)     0           ['tf_upsample_1[0][0]',          
                                                                  'tfc3_1[0][0]']                 
                                                                                                  
 tfc3_5 (TFC3)                  (1, 80, 80, 64)      22720       ['tf_concat_1[0][0]']            
                                                                                                  
 tf_conv_45 (TFConv)            (1, 40, 40, 64)      36928       ['tfc3_5[0][0]']                 
                                                                                                  
 tf_concat_2 (TFConcat)         (1, 40, 40, 128)     0           ['tf_conv_45[0][0]',             
                                                                  'tf_conv_39[0][0]']             
                                                                                                  
 tfc3_6 (TFC3)                  (1, 40, 40, 128)     74112       ['tf_concat_2[0][0]']            
                                                                                                  
 tf_conv_51 (TFConv)            (1, 20, 20, 128)     147584      ['tfc3_6[0][0]']                 
                                                                                                  
 tf_concat_3 (TFConcat)         (1, 20, 20, 256)     0           ['tf_conv_51[0][0]',             
                                                                  'tf_conv_33[0][0]']             
                                                                                                  
 tfc3_7 (TFC3)                  (1, 20, 20, 256)     295680      ['tf_concat_3[0][0]']            
                                                                                                  
 tf_detect (TFDetect)           ((1, 25200, 85),     115005      ['tfc3_5[0][0]',                 
                                 [(1, 6400, 3, 85),               'tfc3_6[0][0]',                 
                                 (1, 1600, 3, 85),                'tfc3_7[0][0]']                 
                                 (1, 400, 3, 85)])                                                
                                                                                                  
==================================================================================================
Total params: 1,867,405
Trainable params: 0
Non-trainable params: 1,867,405
__________________________________________________________________________________________________
2022-05-08 21:29:24.289195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:24.289471: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-05-08 21:29:24.289675: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
2022-05-08 21:29:24.290477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:24.290689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:24.290886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:24.291135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:24.291334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:24.291488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43317 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:06:00.0, compute capability: 8.6
2022-05-08 21:29:24.310606: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize
  function_optimizer: function_optimizer did nothing. time = 0.271ms.
  function_optimizer: function_optimizer did nothing. time = 0.004ms.

2022-05-08 21:29:25.486463: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
Assets written to: yolov5n_saved_model/assets
[34m[1mTensorFlow SavedModel:[0m export success, saved as yolov5n_saved_model (7.4 MB)

Export complete (30.54s)
Results saved to [1m/home/ubuntu/data/repos/yolov5[0m
Detect:          python detect.py --weights yolov5n_saved_model
PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5n_saved_model')
Validate:        python val.py --weights yolov5n_saved_model
Visualize:       https://netron.app
YOLOv5 ðŸš€ v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Loading yolov5n_saved_model for TensorFlow SavedModel inference...
Importing a function (__inference_pruned_6772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
Forcing --batch-size 1 square inference (1,3,640,640) for non-PyTorch models
[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 12[0m[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 12[0m
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|                         Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   2%|â–                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   5%|â–Œ                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   8%|â–Š                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  10%|â–ˆ                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  12%|â–ˆâ–Ž                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  15%|â–ˆâ–                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  17%|â–ˆâ–‹                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  20%|â–ˆâ–ˆ                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  24%|â–ˆâ–ˆâ–                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  27%|â–ˆâ–ˆâ–‹                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  30%|â–ˆâ–ˆâ–ˆ                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  34%|â–ˆâ–ˆâ–ˆâ–Ž                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  37%|â–ˆâ–ˆâ–ˆâ–‹                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  40%|â–ˆâ–ˆâ–ˆâ–‰                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                 Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                 all        128        929      0.738       0.45      0.545      0.342
Speed: 0.2ms pre-process, 17.7ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)
Results saved to [1mruns/val/exp217[0m
YOLOv5 ðŸš€ v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Fusing layers... 
YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs

[34m[1mPyTorch:[0m starting from yolov5n.pt with output shape (1, 25200, 85) (3.9 MB)

[34m[1mTensorFlow SavedModel:[0m starting export with tensorflow 2.8.0...

                 from  n    params  module                                  arguments                     
  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              
  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                
  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   
  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                
  4                -1  1     29184  models.common.C3                        [64, 64, 2]                   
  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  6                -1  1    156928  models.common.C3                        [128, 128, 3]                 
  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 
  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 
 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 12           [-1, 6]  1         0  models.common.Concat                    [1]                           
 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          
 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 16           [-1, 4]  1         0  models.common.Concat                    [1]                           
 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           
 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                
 19          [-1, 14]  1         0  models.common.Concat                    [1]                           
 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]          
 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              
 22          [-1, 10]  1         0  models.common.Concat                    [1]                           
 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]          
 24      [17, 20, 23]  1    115005  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256], [640, 640]]
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_2 (InputLayer)           [(1, 640, 640, 3)]   0           []                               
                                                                                                  
 tf_conv_57 (TFConv)            (1, 320, 320, 16)    1744        ['input_2[0][0]']                
                                                                                                  
 tf_conv_58 (TFConv)            (1, 160, 160, 32)    4640        ['tf_conv_57[0][0]']             
                                                                                                  
 tfc3_8 (TFC3)                  (1, 160, 160, 32)    4704        ['tf_conv_58[0][0]']             
                                                                                                  
 tf_conv_64 (TFConv)            (1, 80, 80, 64)      18496       ['tfc3_8[0][0]']                 
                                                                                                  
 tfc3_9 (TFC3)                  (1, 80, 80, 64)      28928       ['tf_conv_64[0][0]']             
                                                                                                  
 tf_conv_72 (TFConv)            (1, 40, 40, 128)     73856       ['tfc3_9[0][0]']                 
                                                                                                  
 tfc3_10 (TFC3)                 (1, 40, 40, 128)     156288      ['tf_conv_72[0][0]']             
                                                                                                  
 tf_conv_82 (TFConv)            (1, 20, 20, 256)     295168      ['tfc3_10[0][0]']                
                                                                                                  
 tfc3_11 (TFC3)                 (1, 20, 20, 256)     295680      ['tf_conv_82[0][0]']             
                                                                                                  
 tfsppf_1 (TFSPPF)              (1, 20, 20, 256)     164224      ['tfc3_11[0][0]']                
                                                                                                  
 tf_conv_90 (TFConv)            (1, 20, 20, 128)     32896       ['tfsppf_1[0][0]']               
                                                                                                  
 tf_upsample_2 (TFUpsample)     (1, 40, 40, 128)     0           ['tf_conv_90[0][0]']             
                                                                                                  
 tf_concat_4 (TFConcat)         (1, 40, 40, 256)     0           ['tf_upsample_2[0][0]',          
                                                                  'tfc3_10[0][0]']                
                                                                                                  
 tfc3_12 (TFC3)                 (1, 40, 40, 128)     90496       ['tf_concat_4[0][0]']            
                                                                                                  
 tf_conv_96 (TFConv)            (1, 40, 40, 64)      8256        ['tfc3_12[0][0]']                
                                                                                                  
 tf_upsample_3 (TFUpsample)     (1, 80, 80, 64)      0           ['tf_conv_96[0][0]']             
                                                                                                  
 tf_concat_5 (TFConcat)         (1, 80, 80, 128)     0           ['tf_upsample_3[0][0]',          
                                                                  'tfc3_9[0][0]']                 
                                                                                                  
 tfc3_13 (TFC3)                 (1, 80, 80, 64)      22720       ['tf_concat_5[0][0]']            
                                                                                                  
 tf_conv_102 (TFConv)           (1, 40, 40, 64)      36928       ['tfc3_13[0][0]']                
                                                                                                  
 tf_concat_6 (TFConcat)         (1, 40, 40, 128)     0           ['tf_conv_102[0][0]',            
                                                                  'tf_conv_96[0][0]']             
                                                                                                  
 tfc3_14 (TFC3)                 (1, 40, 40, 128)     74112       ['tf_concat_6[0][0]']            
                                                                                                  
 tf_conv_108 (TFConv)           (1, 20, 20, 128)     147584      ['tfc3_14[0][0]']                
                                                                                                  
 tf_concat_7 (TFConcat)         (1, 20, 20, 256)     0           ['tf_conv_108[0][0]',            
                                                                  'tf_conv_90[0][0]']             
                                                                                                  
 tfc3_15 (TFC3)                 (1, 20, 20, 256)     295680      ['tf_concat_7[0][0]']            
                                                                                                  
 tf_detect_1 (TFDetect)         ((1, 25200, 85),     115005      ['tfc3_13[0][0]',                
                                 [(1, 6400, 3, 85),               'tfc3_14[0][0]',                
                                 (1, 1600, 3, 85),                'tfc3_15[0][0]']                
                                 (1, 400, 3, 85)])                                                
                                                                                                  
==================================================================================================
Total params: 1,867,405
Trainable params: 0
Non-trainable params: 1,867,405
__________________________________________________________________________________________________
2022-05-08 21:29:34.474057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:34.474335: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-05-08 21:29:34.474527: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
2022-05-08 21:29:34.474887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:34.475065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:34.475261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:34.475516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:34.475900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:34.476046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43317 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:06:00.0, compute capability: 8.6
2022-05-08 21:29:34.492574: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize
  function_optimizer: function_optimizer did nothing. time = 0.025ms.
  function_optimizer: function_optimizer did nothing. time = 0.003ms.

Assets written to: yolov5n_saved_model/assets
[34m[1mTensorFlow SavedModel:[0m export success, saved as yolov5n_saved_model (7.4 MB)

[34m[1mTensorFlow GraphDef:[0m starting export with tensorflow 2.8.0...
2022-05-08 21:29:36.692746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:36.693053: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-05-08 21:29:36.693233: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
2022-05-08 21:29:36.694005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:36.694227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:36.694420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:36.694678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:36.694885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-08 21:29:36.695038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43317 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:06:00.0, compute capability: 8.6
2022-05-08 21:29:36.711038: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize
  function_optimizer: function_optimizer did nothing. time = 0.024ms.
  function_optimizer: function_optimizer did nothing. time = 0.004ms.

[34m[1mTensorFlow GraphDef:[0m export success, saved as yolov5n.pb (7.3 MB)

Export complete (6.18s)
Results saved to [1m/home/ubuntu/data/repos/yolov5[0m
Detect:          python detect.py --weights yolov5n.pb
PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5n.pb')
Validate:        python val.py --weights yolov5n.pb
Visualize:       https://netron.app
YOLOv5 ðŸš€ v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Loading yolov5n.pb for TensorFlow GraphDef inference...
Forcing --batch-size 1 square inference (1,3,640,640) for non-PyTorch models
[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 12[0m[34m[1mval: [0mScanning '/home/ubuntu/data/repos/datasets/coco128/labels/train2017.cache' images and labels... 12[0m
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|                         Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   2%|â–                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   3%|â–Ž                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   5%|â–Œ                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   9%|â–Š                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  11%|â–ˆ                        Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  14%|â–ˆâ–                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  18%|â–ˆâ–Š                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  21%|â–ˆâ–ˆ                       Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  24%|â–ˆâ–ˆâ–                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  27%|â–ˆâ–ˆâ–‹                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  30%|â–ˆâ–ˆâ–ˆ                      Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  34%|â–ˆâ–ˆâ–ˆâ–Ž                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  36%|â–ˆâ–ˆâ–ˆâ–Œ                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  38%|â–ˆâ–ˆâ–ˆâ–Š                     Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                    Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                 Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                 all        128        929      0.738       0.45      0.545      0.342
Speed: 0.2ms pre-process, 16.4ms inference, 1.7ms NMS per image at shape (1, 3, 640, 640)
Results saved to [1mruns/val/exp218[0m
WARNING: Benchmark failure for TensorFlow Lite: TensorFlow Lite inference not supported on GPU
WARNING: Benchmark failure for TensorFlow Edge TPU: Edge TPU not supported
WARNING: Benchmark failure for TensorFlow.js: TF.js not supported


[34m[1mbenchmarks: [0mweights=yolov5n.pt, imgsz=640, batch_size=1, data=/home/ubuntu/data/repos/yolov5/data/coco128.yaml, device=0, half=False, test=False, pt_only=False
Checking setup...
[2KYOLOv5 ðŸš€ v6.1-177-g26a6b2a torch 1.10.1+cu113 CUDA:0 (NVIDIA RTX A6000, 48685MiB)

Benchmarks complete (592.18s)
                   Format  mAP@0.5:0.95  Inference time (ms)
0                 PyTorch        0.3419                 6.97
1             TorchScript        0.3419                 5.09
2                    ONNX        0.3420                 7.10
3                OpenVINO           NaN                  NaN
4                TensorRT        0.3423                 0.84
5                  CoreML           NaN                  NaN
6   TensorFlow SavedModel        0.3420                17.74
7     TensorFlow GraphDef        0.3420                16.41
8         TensorFlow Lite           NaN                  NaN
9     TensorFlow Edge TPU           NaN                  NaN
10          TensorFlow.js           NaN                  NaN
[2KSetup complete âœ… (14 CPUs, 98.2 GB RAM, 31.7/992.3 GB disk)
